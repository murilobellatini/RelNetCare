{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!source /home/murilo/RelNetCare/.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing BERT model and tokenizer...\n",
      "max_length= 512\n",
      "Moving model into device=cuda...\n",
      "Starting to loop over JSON files in /home/murilo/RelNetCare/data/processed/dialog-re-ddrel...\n",
      "Reading /home/murilo/RelNetCare/data/processed/dialog-re-ddrel/train.json...\n",
      "Breaking data into batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 2/764 [00:00<03:41,  3.43it/s, % Exceeding Max Length=0.00% (0 / 16)]Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
      "Processing batches: 100%|██████████| 764/764 [02:27<00:00,  5.18it/s, % Exceeding Max Length=1.95% (119 / 6110)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/murilo/RelNetCare/data/processed/dialog-re-ddrel/dev.json...\n",
      "Breaking data into batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 127/127 [00:26<00:00,  4.83it/s, % Exceeding Max Length=1.99% (142 / 7121)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/murilo/RelNetCare/data/processed/dialog-re-ddrel/test.json...\n",
      "Breaking data into batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 121/121 [00:25<00:00,  4.73it/s, % Exceeding Max Length=2.03% (164 / 8088)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for exceeeded max length...\n",
      "Creating DataFrame...\n",
      "Creating DataFrame...\n",
      "Saving DataFrame to /home/murilo/RelNetCare/data/processed/dialog-re-ddrel/df_embeddings.pkl...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from src.paths import LOCAL_PROCESSED_DATA_PATH\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize BERT model and tokenizer\n",
    "print(\"Initializing BERT model and tokenizer...\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertModel.from_pretrained('bert-large-uncased')\n",
    "max_length = tokenizer.model_max_length  # Get the max_length from the tokenizer\n",
    "print(\"max_length=\",max_length)\n",
    "print(f\"Moving model into device={device}...\")\n",
    "model.to(device)\n",
    "\n",
    "# Placeholder for storing results\n",
    "df_list = []\n",
    "\n",
    "# Batch size\n",
    "batch_size = 8\n",
    "exceed_count = 0  # Counter for dialogues exceeding max_length\n",
    "total_count = 0   # Total number of dialogues\n",
    "\n",
    "# Loop over JSON files\n",
    "data_path = LOCAL_PROCESSED_DATA_PATH / 'dialog-re-ddrel'\n",
    "print(f\"Starting to loop over JSON files in {data_path}...\")\n",
    "for file in glob.glob(str(data_path / \"*.json\")):\n",
    "    print(f\"Reading {file}...\")\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    dialogues = ['\\n'.join(d[0]) for d in data]\n",
    "    # dialogues = [re.sub(r\"Speaker (\\d+):\", r\"S\\1:\", ' '.join(d[0])) for d in data]\n",
    "    # dialogues = [re.sub(r\"Speaker (\\d+):\", r\"S\\1:\", json.dumps(d[0], indent=0)) for d in data]\n",
    "    relations = [re.sub(r\"Speaker (\\d+):\", r\"S\\1:\", json.dumps(d[1], indent=0)) for d in data]\n",
    "\n",
    "    # Break data into batches\n",
    "    print(\"Breaking data into batches...\")\n",
    "    num_batches = int(np.ceil(len(dialogues) / float(batch_size)))\n",
    "    pbar = tqdm(range(num_batches), desc=\"Processing batches\")\n",
    "    for i in pbar:\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, len(dialogues))\n",
    "\n",
    "        dialogues_batch = dialogues[start_idx:end_idx]\n",
    "        relations_batch = relations[start_idx:end_idx]\n",
    "\n",
    "        # Check if any token lengths exceed max length\n",
    "        for dialogue in dialogues_batch:\n",
    "            total_count += 1\n",
    "            input_len = len(tokenizer.encode(dialogue))\n",
    "            if input_len > max_length:\n",
    "                exceed_count += 1\n",
    "\n",
    "        pct_exceed = (exceed_count / total_count) * 100\n",
    "        pbar.set_postfix({\"% Exceeding Max Length\": f\"{pct_exceed:.2f}% ({exceed_count} / {total_count})\"}, refresh=True)\n",
    "\n",
    "        # Tokenize and generate tensor for each batch\n",
    "        inputs = tokenizer(dialogues_batch, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")  # Set max_length here\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "        # Generate BERT embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # Get the [CLS] token embedding\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "        for j in range(len(dialogues_batch)):\n",
    "            df_list.append({\n",
    "                'dialogue': dialogues_batch[j],\n",
    "                'relation': relations_batch[j],\n",
    "                'embedding': cls_embeddings[j],\n",
    "                'dataset': str(file).split('/')[-1].replace('.json','')\n",
    "            })\n",
    "\n",
    "\n",
    "# Re-tokenize dialogues and check if they exceed max_length\n",
    "print(\"Checking for exceeeded max length...\")\n",
    "for i, row in enumerate(df_list):\n",
    "    input_len = len(tokenizer.encode(row['dialogue']))\n",
    "    exceed_flag = input_len > max_length\n",
    "    df_list[i]['exceeded_max_length'] = exceed_flag\n",
    "\n",
    "# Create DataFrame\n",
    "print(\"Creating DataFrame...\")\n",
    "df = pd.DataFrame(df_list)\n",
    "\n",
    "# Create DataFrame\n",
    "print(\"Creating DataFrame...\")\n",
    "df = pd.DataFrame(df_list)\n",
    "\n",
    "# Save as a pickle file\n",
    "print(f\"Saving DataFrame to {data_path / 'df_embeddings.pkl'}...\")\n",
    "df.to_pickle(data_path / \"df_embeddings_original.pkl\")\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>relation</th>\n",
       "      <th>embedding</th>\n",
       "      <th>dataset</th>\n",
       "      <th>exceeded_max_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Speaker 1: It's been an hour and not one of my...</td>\n",
       "      <td>[\\n{\\n\"x\": \"Speaker 2\",\\n\"y\": \"Chandler Bing\",...</td>\n",
       "      <td>[0.54284745, -0.70306915, -1.3126775, -0.05009...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Speaker 1: So, eh... it's probably gonna be ha...</td>\n",
       "      <td>[\\n{\\n\"x\": \"Speaker 2\",\\n\"y\": \"Boston\",\\n\"rid\"...</td>\n",
       "      <td>[0.049894452, -0.66197634, -0.48381886, -0.193...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Speaker 1: Hi!\\nSpeaker 2: Hi!\\nSpeaker 1: So ...</td>\n",
       "      <td>[\\n{\\n\"x\": \"Speaker 2\",\\n\"y\": \"goodie-goodie\",...</td>\n",
       "      <td>[0.31069955, -0.4959651, -0.99742293, -0.19498...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speaker 1: Hi.\\nSpeaker 2: Hi.\\nSpeaker 1: I j...</td>\n",
       "      <td>[\\n{\\n\"x\": \"Phoebe\",\\n\"y\": \"Mike\",\\n\"rid\": [\\n...</td>\n",
       "      <td>[0.41672152, -0.71111834, -1.2734727, -0.16772...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Speaker 1: 'Okay. Okay, daddy we'll see you to...</td>\n",
       "      <td>[\\n{\\n\"x\": \"Speaker 2\",\\n\"y\": \"wethead\",\\n\"rid...</td>\n",
       "      <td>[0.25623024, -0.26421997, -1.0316484, -0.06013...</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8083</th>\n",
       "      <td>Speaker 1: I feel like you're turning me into ...</td>\n",
       "      <td>[\\n{\\n\"x\": \"Speaker 1\",\\n\"x_type\": \"PER\",\\n\"y\"...</td>\n",
       "      <td>[0.20662983, -0.22525145, -0.7552583, -0.35369...</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8084</th>\n",
       "      <td>Speaker 1: You have to go.  I mean it.\\nSpeake...</td>\n",
       "      <td>[\\n{\\n\"x\": \"Speaker 1\",\\n\"x_type\": \"PER\",\\n\"y\"...</td>\n",
       "      <td>[0.1891077, -0.5775761, -0.543093, -0.07402149...</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8085</th>\n",
       "      <td>Speaker 1: You're crazier than I thought, Lenn...</td>\n",
       "      <td>[\\n{\\n\"x\": \"Speaker 1\",\\n\"x_type\": \"PER\",\\n\"y\"...</td>\n",
       "      <td>[0.07690117, -0.59195894, -0.9255361, 0.373093...</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8086</th>\n",
       "      <td>Speaker 1: What's going on?\\nSpeaker 2: Faith,...</td>\n",
       "      <td>[\\n{\\n\"x\": \"Speaker 1\",\\n\"x_type\": \"PER\",\\n\"y\"...</td>\n",
       "      <td>[-0.2005296, -0.42849943, -1.0686105, -0.01745...</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8087</th>\n",
       "      <td>Speaker 1: So finally he gives Iris some cash ...</td>\n",
       "      <td>[\\n{\\n\"x\": \"Speaker 1\",\\n\"x_type\": \"PER\",\\n\"y\"...</td>\n",
       "      <td>[0.1252722, -0.7021356, -1.0729774, -0.3243806...</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7924 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               dialogue  \\\n",
       "0     Speaker 1: It's been an hour and not one of my...   \n",
       "1     Speaker 1: So, eh... it's probably gonna be ha...   \n",
       "2     Speaker 1: Hi!\\nSpeaker 2: Hi!\\nSpeaker 1: So ...   \n",
       "3     Speaker 1: Hi.\\nSpeaker 2: Hi.\\nSpeaker 1: I j...   \n",
       "4     Speaker 1: 'Okay. Okay, daddy we'll see you to...   \n",
       "...                                                 ...   \n",
       "8083  Speaker 1: I feel like you're turning me into ...   \n",
       "8084  Speaker 1: You have to go.  I mean it.\\nSpeake...   \n",
       "8085  Speaker 1: You're crazier than I thought, Lenn...   \n",
       "8086  Speaker 1: What's going on?\\nSpeaker 2: Faith,...   \n",
       "8087  Speaker 1: So finally he gives Iris some cash ...   \n",
       "\n",
       "                                               relation  \\\n",
       "0     [\\n{\\n\"x\": \"Speaker 2\",\\n\"y\": \"Chandler Bing\",...   \n",
       "1     [\\n{\\n\"x\": \"Speaker 2\",\\n\"y\": \"Boston\",\\n\"rid\"...   \n",
       "2     [\\n{\\n\"x\": \"Speaker 2\",\\n\"y\": \"goodie-goodie\",...   \n",
       "3     [\\n{\\n\"x\": \"Phoebe\",\\n\"y\": \"Mike\",\\n\"rid\": [\\n...   \n",
       "4     [\\n{\\n\"x\": \"Speaker 2\",\\n\"y\": \"wethead\",\\n\"rid...   \n",
       "...                                                 ...   \n",
       "8083  [\\n{\\n\"x\": \"Speaker 1\",\\n\"x_type\": \"PER\",\\n\"y\"...   \n",
       "8084  [\\n{\\n\"x\": \"Speaker 1\",\\n\"x_type\": \"PER\",\\n\"y\"...   \n",
       "8085  [\\n{\\n\"x\": \"Speaker 1\",\\n\"x_type\": \"PER\",\\n\"y\"...   \n",
       "8086  [\\n{\\n\"x\": \"Speaker 1\",\\n\"x_type\": \"PER\",\\n\"y\"...   \n",
       "8087  [\\n{\\n\"x\": \"Speaker 1\",\\n\"x_type\": \"PER\",\\n\"y\"...   \n",
       "\n",
       "                                              embedding dataset  \\\n",
       "0     [0.54284745, -0.70306915, -1.3126775, -0.05009...   train   \n",
       "1     [0.049894452, -0.66197634, -0.48381886, -0.193...   train   \n",
       "2     [0.31069955, -0.4959651, -0.99742293, -0.19498...   train   \n",
       "3     [0.41672152, -0.71111834, -1.2734727, -0.16772...   train   \n",
       "4     [0.25623024, -0.26421997, -1.0316484, -0.06013...   train   \n",
       "...                                                 ...     ...   \n",
       "8083  [0.20662983, -0.22525145, -0.7552583, -0.35369...    test   \n",
       "8084  [0.1891077, -0.5775761, -0.543093, -0.07402149...    test   \n",
       "8085  [0.07690117, -0.59195894, -0.9255361, 0.373093...    test   \n",
       "8086  [-0.2005296, -0.42849943, -1.0686105, -0.01745...    test   \n",
       "8087  [0.1252722, -0.7021356, -1.0729774, -0.3243806...    test   \n",
       "\n",
       "      exceeded_max_length  \n",
       "0                   False  \n",
       "1                   False  \n",
       "2                   False  \n",
       "3                   False  \n",
       "4                   False  \n",
       "...                   ...  \n",
       "8083                False  \n",
       "8084                False  \n",
       "8085                False  \n",
       "8086                False  \n",
       "8087                False  \n",
       "\n",
       "[7924 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
