{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForSequenceClassification:\n\tMissing key(s) in state_dict: \"classifier.0.weight\", \"classifier.0.bias\". \n\tUnexpected key(s) in state_dict: \"classifier.weight\", \"classifier.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m model_path\u001b[39m=\u001b[39mLOCAL_MODELS_PATH \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfine-tuned/dialogre-fine-tuned/bert_base/model_best.pt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     40\u001b[0m relation_label_dict \u001b[39m=\u001b[39m LOCAL_RAW_DATA_PATH \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdialog-re/relation_label_dict.json\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 42\u001b[0m inferer \u001b[39m=\u001b[39m EntityRelationInferer(\n\u001b[0;32m     43\u001b[0m     bert_config_file \u001b[39m=\u001b[39;49m bert_config_file, \n\u001b[0;32m     44\u001b[0m     vocab_file \u001b[39m=\u001b[39;49m vocab_file, \n\u001b[0;32m     45\u001b[0m     model_path \u001b[39m=\u001b[39;49m model_path, \n\u001b[0;32m     46\u001b[0m     relation_type_count \u001b[39m=\u001b[39;49m relation_type_count, \n\u001b[0;32m     47\u001b[0m     relation_label_dict \u001b[39m=\u001b[39;49m relation_label_dict,\n\u001b[0;32m     48\u001b[0m     T2 \u001b[39m=\u001b[39;49m T2)\n\u001b[0;32m     50\u001b[0m rid_prediction, relation_label \u001b[39m=\u001b[39m inferer\u001b[39m.\u001b[39minfer_relations(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(dialogue_list), ent_x, ent_y)\n\u001b[0;32m     52\u001b[0m model_path \u001b[39m=\u001b[39m LOCAL_MODELS_PATH \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcustom/relation-identification/xgboost/dialog-re-binary-enriched\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\muril\\documents\\github\\relnetcare\\src\\infering.py:60\u001b[0m, in \u001b[0;36mEntityRelationInferer.__init__\u001b[1;34m(self, bert_config_file, vocab_file, model_path, T2, relation_type_count, max_seq_length, relation_label_dict, do_lower_case, device)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert_config \u001b[39m=\u001b[39m BertConfig\u001b[39m.\u001b[39mfrom_json_file(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert_config_file)\n\u001b[0;32m     59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m BertForSequenceClassification(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert_config, \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelation_type_count)\n\u001b[1;32m---> 60\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_path, map_location\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice))\n\u001b[0;32m     61\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()  \u001b[39m# Set model to evaluation mode\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)  \u001b[39m# Move model to device once\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\muril\\.virtualenvs\\RelNetCare-pBkonNa4\\lib\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForSequenceClassification:\n\tMissing key(s) in state_dict: \"classifier.0.weight\", \"classifier.0.bias\". \n\tUnexpected key(s) in state_dict: \"classifier.weight\", \"classifier.bias\". "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from src.paths import LOCAL_MODELS_PATH\n",
    "from src.processing.text_preprocessing import DialogueEnricher\n",
    "\n",
    "from src.infering import EntityRelationInferer\n",
    "from src.processing.dialogre_processing import DialogREDatasetTransformer\n",
    "from src.paths import LOCAL_MODELS_PATH, LOCAL_PROCESSED_DATA_PATH, LOCAL_RAW_DATA_PATH\n",
    "\n",
    "dialogue_list = [\n",
    "    \"Speaker 1: A new place for a new Ross. I'm gonna have you and all the guys from work over once it's y'know, furnished.\",\n",
    "    \"Speaker 2: I must say it's nice to see you back on your feet.\",\n",
    "    \"Speaker 1: Well I am that. And that whole rage thing is definitely behind me.\",\n",
    "    \"Speaker 2: I wonder if its time for you to rejoin our team at the museum?\",\n",
    "    \"Speaker 1: Oh Donald that-that would be great. I am totally ready to come back to work. I—What? No! Wh… What are you doing?!!  GET OFF MY SISTER!!!!!!!!!!!!!\"\n",
    "    ]\n",
    "relation = {\n",
    "    \"y\": \"museum\",\n",
    "    \"x\": \"Speaker 1\",\n",
    "    \"rid\": [\n",
    "    28\n",
    "    ],\n",
    "    \"r\": [\n",
    "    \"per:place_of_work\"\n",
    "    ],\n",
    "    \"t\": [\n",
    "    \"rejoin\"\n",
    "    ],\n",
    "    \"x_type\": \"PER\",\n",
    "    \"y_type\": \"STRING\"\n",
    "}\n",
    "\n",
    "ent_x, ent_y = relation['x'], relation['y']\n",
    "\n",
    "T2 = 0.32\n",
    "relation_type_count = 36\n",
    "bert_config_file = LOCAL_MODELS_PATH / \"downloaded/bert-base/bert_config.json\"\n",
    "vocab_file = LOCAL_MODELS_PATH / \"downloaded/bert-base/vocab.txt\"\n",
    "model_path=LOCAL_MODELS_PATH / \"fine-tuned/dialogre-fine-tuned/bert_base/model_best.pt\"\n",
    "relation_label_dict = LOCAL_RAW_DATA_PATH / 'dialog-re/relation_label_dict.json'\n",
    "\n",
    "inferer = EntityRelationInferer(\n",
    "    bert_config_file = bert_config_file, \n",
    "    vocab_file = vocab_file, \n",
    "    model_path = model_path, \n",
    "    relation_type_count = relation_type_count, \n",
    "    relation_label_dict = relation_label_dict,\n",
    "    T2 = T2)\n",
    "\n",
    "rid_prediction, relation_label = inferer.infer_relations(' '.join(dialogue_list), ent_x, ent_y)\n",
    "\n",
    "model_path = LOCAL_MODELS_PATH / 'custom/relation-identification/xgboost/dialog-re-binary-enriched'\n",
    "\n",
    "def load_model(path):\n",
    "    model = pickle.load(open(os.path.join(path, 'model.pkl'), 'rb'))\n",
    "    le_dict = pickle.load(open(os.path.join(path, 'label_encoder_dict.pkl'), 'rb'))\n",
    "    vectorizer = pickle.load(open(os.path.join(path, 'vectorizer.pkl'), 'rb'))\n",
    "    scaler = pickle.load(open(os.path.join(path, 'scaler.pkl'), 'rb'))\n",
    "    return model, le_dict, vectorizer, scaler\n",
    "\n",
    "enricher = DialogueEnricher()\n",
    "\n",
    "model, le_dict, vectorizer, scaler = load_model(model_path)\n",
    "\n",
    "\n",
    "le_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['Speaker 1: Hey!',\n",
       "   'Speaker 2: Hey.',\n",
       "   \"Speaker 3: Hey, man. What's up?\",\n",
       "   \"Speaker 1: Maybe you can tell me. My agent would like to know why I didn't show up at the audition I didn't know I had today. The first good thing she gets me in weeks. How could you not give me the message?!\",\n",
       "   \"Speaker 3: Well, I'll tell ya I do enjoy guilt, but, ah, it wasn't me.\",\n",
       "   'Speaker 2: Yes, it was! It was him! Uh huh! Okay, it was me!',\n",
       "   'Speaker 1: How is it you?',\n",
       "   \"Speaker 2: Well, it was just, it was all so crazy, you know. I mean, Chandler was in the closet, counting to 10, and he was up to 7 and I hadn't found a place to hide yet. I-I-I meant to tell you, and I wrote it all down on my hand. See, all of it.\",\n",
       "   \"Speaker 1: Yep, that's my audition.\",\n",
       "   'Speaker 4: See, now this is why I keep notepads everywhere.',\n",
       "   \"Speaker 2: Yep, and that's why we don't invite you to play.\",\n",
       "   'Speaker 5: What is the great tragedy here? You go get yourself another appointment.',\n",
       "   'Speaker 1: Well, Estelle tried, you know. The casting director told her that I missed my chance.',\n",
       "   \"Speaker 2: That is unfair. I'll call her and tell her it was totally my fault.\",\n",
       "   \"Speaker 1: Pheebs, you can't do that. The casting director doesn't talk to friends, she only talks to agents.\",\n",
       "   'Speaker 2: What a sad little life she must lead. Okay, ooh.',\n",
       "   'Speaker 1: What, what are you doing? What are you doing?',\n",
       "   \"Speaker 2: No, no, no, I know, I know, ooh. 'Hi, this is Katelynn, from Phoebe Buffay's office. Um, is um, Ann there for Phoebe, she'll know what it's about.'\",\n",
       "   'Speaker 1: Hang up, hang up.',\n",
       "   \"Speaker 2: 'Annie! Hi. Listen we got a problem with Joey Tribbiani, apparently he missed his audition. Who did you speak to in my office? Estelle, no, I don't know what I'm going to do with her. No. All right, so your husband leaves and burns down the apartment, the world does not stop.'\",\n",
       "   'Speaker 3: Is anybody else scared?',\n",
       "   \"Speaker 2: 'Right, well look, um, if Joey loses this audition, that is it for Estelle. I don't care! Annie you are a doll, what time can you see him?' I need a pen.\",\n",
       "   'Speaker 3: Get the woman a pad! Get the woman a pad! A pad! A pad!',\n",
       "   'Speaker 4: Oh, now you want a pad.'],\n",
       "  [{'y': 'casting director',\n",
       "    'x': 'Ann',\n",
       "    'x_type': 'PER',\n",
       "    'y_type': 'STRING',\n",
       "    'x_token_span': (269, 313),\n",
       "    'y_token_span': (391, 392),\n",
       "    'x_char_span': (966, 1154),\n",
       "    'y_char_span': (1430, 1433),\n",
       "    'min_words_distance': 81,\n",
       "    'min_words_distance_pct': 0.038553069966682535,\n",
       "    'spacy_features': {'x_pos': 'VERB',\n",
       "     'x_dep': 'amod',\n",
       "     'x_tag': 'VBG',\n",
       "     'y_pos': 'PROPN',\n",
       "     'y_dep': 'npadvmod',\n",
       "     'y_tag': 'NNP'},\n",
       "    'min_turn_distance': 3,\n",
       "    'min_turn_distance_pct': 0.0014278914802475012}])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_dialogues = enricher.enrich(dialogues)\n",
    "enriched_dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\muril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.71it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'y': 'casting director',\n",
       "  'x': 'Ann',\n",
       "  'x_type': 'PER',\n",
       "  'y_type': 'STRING',\n",
       "  'x_token_span': (269, 313),\n",
       "  'y_token_span': (391, 392),\n",
       "  'x_char_span': (966, 1154),\n",
       "  'y_char_span': (1430, 1433),\n",
       "  'min_words_distance': 81,\n",
       "  'min_words_distance_pct': 0.038553069966682535,\n",
       "  'spacy_features': {'x_pos': 'VERB',\n",
       "   'x_dep': 'amod',\n",
       "   'x_tag': 'VBG',\n",
       "   'y_pos': 'PROPN',\n",
       "   'y_dep': 'npadvmod',\n",
       "   'y_tag': 'NNP'},\n",
       "  'min_turn_distance': 3,\n",
       "  'min_turn_distance_pct': 0.0014278914802475012}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_dialogues[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RelNetCare-pBkonNa4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
